version: 2.1
orbs:
  slack: circleci/slack@4.9.3

commands:
  destroy-environment:
    description: Destroy back-end and front-end cloudformation stacks given a workflow ID.
    steps:
      - run:
          name: Destroy environments
          when: on_fail
          command: |
            aws cloudformation delete-stack --stack-name UdaPeople-Backend-${CIRCLE_WORKFLOW_ID}
            aws cloudformation delete-stack --stack-name UdaPeople-Frontend-${CIRCLE_WORKFLOW_ID}

  revert-migrations:
    description: Revert the last migration if successfully run in the current workflow.
    steps:
      - run:
          name: Revert migrations
          when: on_fail
          command: |
            # get migration status from AWS SSM Parameter store
            MIGRATION_STATUS=$(aws ssm get-parameter --name udapeople_migration_${CIRCLE_WORKFLOW_ID} --query 'Parameter.Value' --output text)

            if [ $MIGRATION_STATUS == 'FAIL' ]
              then
                echo "Migration FAILED, Revert Migration"
                cd ~/project/backend
                npm install
                npm run migrations:revert
                exit 1
            fi

jobs:
  build-frontend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys: 
            - frontend-build002
      - run:
          name: Install Frontend Dependencies
          command: |
            cd frontend
            echo "Install Dependencies"
            npm install
      - save_cache:
          paths: 
            - frontend/node_modules
          key: frontend-build002
      - run:
          name: Build Frontend
          command: |
            cd frontend
            echo "Build frontend"
            npm run build
            echo "frontend compiled files"
            ls dist
      - persist_to_workspace:
          root: ~/
          paths:
            - project/frontend/dist
      - slack/notify:
          event: fail
          template: basic_fail_1
      - slack/notify:
          event: pass
          template: success_tagged_deploy_1

  test-frontend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys: 
            - frontend-build002
      - run:
          name: Test front-end
          command: |
            cd frontend
            npm test

  scan-frontend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys: 
            - frontend-build002
      - run:
          name: Front-end Scan with force fix
          command: |
            cd frontend
            npm install
            npm audit fix --audit-level=critical --force
            npm audit --audit-level=critical


  build-backend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys:
            - backend-build002
      - run:
          name: Back-end build
          command: |
             cd backend
             npm install
             npm run build
             echo "backend compiled files"
             ls dist
      - save_cache:
          paths: 
            - backend/node_modules
            - backend/dist
          key: backend-build002
      - slack/notify:
          event: fail
          template: basic_fail_1
      - slack/notify:
          event: pass
          template: success_tagged_deploy_1

  test-backend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys:
            - backend-build002
      - run:
          name: Back-end Test
          command: |
             cd backend
             npm test

  scan-backend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys:
            - backend-build002
      - run:
          name: Back-end Scan with force fix
          command: |
            cd backend
            npm audit fix --audit-level=critical --force
            npm install --save-dev webpack@5.74.0
            npm update mkdirp --depth 2
            npm audit --audit-level=critical

  deploy-infrastructure:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Ensure back-end infrastructure exists
          command: |
            aws cloudformation deploy \
              --template-file .circleci/files/backend.yml \
              --tags project=UdaPeople-project-backend \
              --stack-name UdaPeople-Backend-${CIRCLE_WORKFLOW_ID} \
              --parameter-overrides ID=${CIRCLE_WORKFLOW_ID}
          no_output_timeout: 20m
      - run:
          name: Ensure front-end infrastructure exist
          command: |
            aws cloudformation deploy \
              --template-file .circleci/files/frontend.yml \
              --tags project=UdaPeople-project-frontend \
              --stack-name UdaPeople-Frontend-${CIRCLE_WORKFLOW_ID} \
              --parameter-overrides ID=${CIRCLE_WORKFLOW_ID}
          no_output_timeout: 20m
      - run:
          name: Install dependencies
          command: |
            yum install -y openssh-client ca-certificates tar gzip git curl wget
      - run:
          name: Add back-end ip to ansible inventory
          command: |
            pwd
            ec2TagValue="backend-${CIRCLE_WORKFLOW_ID}"
            aws ec2 describe-instances \
              --query 'Reservations[*].Instances[*].PublicDnsName' \
              --filters "Name=tag:Name,Values=$ec2TagValue" \
              --output text >> .circleci/ansible/inventory.txt
            cat .circleci/ansible/inventory.txt
      - run:
          name: get backend server url
          command: |
            ec2TagValue="backend-${CIRCLE_WORKFLOW_ID}"
            aws ec2 describe-instances \
              --query 'Reservations[*].Instances[*].PublicDnsName' \
              --filters "Name=tag:Name,Values=$ec2TagValue" \
              --output text > backend-domain-${CIRCLE_WORKFLOW_ID}.txt
      - persist_to_workspace:
          root: ~/
          paths:
            - project/.circleci/ansible/inventory.txt
            - project/backend-domain-${CIRCLE_WORKFLOW_ID}.txt
      - run:
          name: Save backend server url to AWS SSM
          command: |
            ec2TagValue="backend-${CIRCLE_WORKFLOW_ID}"
            BACKEND_URL=$(aws ec2 describe-instances \
              --query 'Reservations[*].Instances[*].PublicDnsName' \
              --filters "Name=tag:Name,Values=$ec2TagValue" \
              --output text)
            aws ssm put-parameter --name BACKEND_URL_${CIRCLE_WORKFLOW_ID} \
              --type "String" --tier Standard --value $BACKEND_URL
      - destroy-environment

  configure-infrastructure:
    docker:
      - image: circleci/python:3.9
    steps:
      - checkout
      - add_ssh_keys:
          fingerprints:
            - "14:a6:8e:e5:27:28:87:50:8c:bd:06:96:1b:42:cc:e0"
      - attach_workspace:
          at: ~/project
      - run:
          name: Install ansible
          command: |
            pip install ansible
      - run:
          name: Configure server
          command: |
            pwd
            ls
            echo "check .circleci/ansible/inventory.txt"
            cat .circleci/ansible/inventory.txt
            echo "check project"
            cat project/.circleci/ansible/inventory.txt
            ansible-playbook -i project/.circleci/ansible/inventory.txt .circleci/ansible/configure-server.yml
      #ansible-playbook -i .circleci/ansible/inventory.txt .circleci/ansible/deploy-backend.yml
      # Here's where you will add some code to rollback on failure   
  
  run-migrations:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - run:
          name: Run migrations
          command: |
            cd backend
            npm run migrations > migration_output.log
            cat migration_output.log
            grep "has been executed successfully" migration_output.log
      - run:
          name: Install aws cli
          command: |
            cd /tmp
            curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
            unzip awscliv2.zip
            sudo ./aws/install
      - run:
          name: save migration results to aws ssm parameter store
          command: |
            cd backend
            grep "has been executed successfully" migration_output.log
            if [ $? -eq 0 ]
              then
                echo "migration_${CIRCLE_WORKFLOW_ID} SUCCESS"
                aws ssm put-parameter --name udapeople_migration_${CIRCLE_WORKFLOW_ID} --type "String" --tier Standard --value "SUCCESS"
              else
                echo "migration_${CIRCLE_WORKFLOW_ID} Fail"
                aws ssm put-parameter --name udapeople_migration_${CIRCLE_WORKFLOW_ID} --type "String" --tier Standard --value "FAIL"
                exit 1
            fi
      - revert-migrations
workflows:
  udapeople:
    jobs:
      - build-frontend:
          context: slack-secret
      - build-backend:
          context: slack-secret
      - test-frontend:
          requires: [build-frontend]
      - test-backend:
          requires: [build-backend]
      - scan-frontend:
          requires: [build-frontend]
      - scan-backend:
          requires: [build-backend]
      - deploy-infrastructure:
          requires: [test-frontend, test-backend, scan-frontend, scan-backend]
      - configure-infrastructure:
          requires: [deploy-infrastructure]
      - run-migrations:
          requires: [configure-infrastructure]
